source("moves.R")
source("prior.R")
source("subroutines.R")
sourceCpp("cpp_subroutines.cpp")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
## Unhash these for regular run
#init <- initialize(init_mst = T)
init <- initialize()
mcmc <- init[[1]]
data <- init[[2]]
data$n_local = 10
data$sample_every = 10
data$n_global = 1
#mcmc$psi <- 0.1 / (1.5 + 0.1)
## Unhash these for run on pre-computed data and initial MCMC
# load("data.RData")
# load("mcmc.RData")
output <- list()
liks <- c()
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Chop up the tree into pieces
breakdowns <- breakdown(mcmc, data)
mcmcs <- breakdowns[[1]]
datas <- breakdowns[[2]]
message(paste("Parallelizing over", length(mcmcs), "cores..."))
mcmc <- mcmcs[[1]]
data <- datas[[1]]
# Move 11
mcmc <- moves$w(mcmc, data)
# Move 12
mcmc <- moves$t(mcmc, data)
# Move 13
mcmc <- moves$w_t(mcmc, data)
# Move 14
mcmc <- moves$h_step(mcmc, data)
# Move 15
mcmc <- moves$h_step(mcmc, data, upstream = F)
# Move 16
mcmc <- moves$h_step(mcmc, data, resample_t = T)
# Move 17
mcmc <- moves$h_step(mcmc, data, upstream = F, resample_t = T)
# Move 18
mcmc <- moves$h_step(mcmc, data, resample_t = T, resample_w = T)
# Move 19
mcmc <- moves$h_step(mcmc, data, upstream = F, resample_t = T, resample_w = T)
# Move 20
mcmc <- moves$h_global(mcmc, data)
# Move 21
mcmc <- moves$swap(mcmc, data)
# Move 22
mcmc <- moves$swap(mcmc, data, exchange_children = T)
# Move 23
mcmc <- moves$genotype(mcmc, data)
create = T
upstream = T
# Pick any node with an ancestor. (Note, some choices impossible, but this is okay!)
j1 <- sample(2:mcmc$n, 1)
h <- mcmc$h[j1]
mcmc$w[j1] == 0 | (upstream & mcmc$d[h] == 1) | (!upstream & mcmc$d[j1] == 0)
# Who else are we attaching to i?
if(upstream){
kids <- setdiff(which(mcmc$h == h), j1)
}else{
kids <- which(mcmc$h == j1)
}
data$p_move
j2s <- kids[runif(length(kids)) < data$p_move]
js <- c(j1, j2s)
# How far upstream from h is the new node?
# Maximum is min(w[js]) - 1 to preserve sum of all edge weights
if(upstream){
max_dist <- min(mcmc$w[js]) - 1
}else{
max_dist <- mcmc$w[j1] - 1
}
# New edge weight coming into i, the new host
dist <- sample(0:max_dist, 1)
i <- mcmc$n + 1
# Maximum time i could be infected
max_t <- min(mcmc$t[js])
# Proposal
prop <- mcmc
## Stick i onto h
prop$n <- mcmc$n + 1
prop$h[i] <- h
prop$w[i] <- dist
prop$t[i] <- mcmc$t[h] + (max_t - mcmc$t[h]) * rbeta(1, dist + 1, max_dist - dist + 1) # Weighted average
prop$d[i] <- 0
prop$d[h] <- mcmc$d[h] + 1
i
## Initialize genotype for i. This is all changing, so we initialize as i loses all iSNVs to 0. Everything else stays the same
prop$mx0[[i]] <- unique(c(
mcmc$mx0[[j1]], mcmc$mxy[[j1]], mcmc$mx1[[j1]]
))
prop$mx0[[i]]
prop$m01[[i]] <- character(0)
prop$m10[[i]] <- character(0)
prop$m0y[[i]] <- character(0)
prop$m1y[[i]] <- character(0)
prop$mx1[[i]] <- character(0)
prop$mxy[[i]] <- character(0)
## Move all js onto i
if(upstream){
for (j in js) {
prop <- shift_upstream(prop, data, j, h, i)
}
}else{
prop <- shift_upstream(prop, data, j1, h, i)
for (j2 in j2s) {
prop <- shift_downstream(prop, data, j2, j1, i)
}
}
prop$h
prop$m01
prop$m10
mcmc$m10
mcmc$h
mcmc$h[145]
## Create new genotype for i
geno <- genotype(prop, i, js, data$eps)
prop <- geno[[1]]
prop$m10
mcmc$m01
mcmc$m01
prop$m01
prop$m01
mcmc$m01
prop$m01[[172]]
prop$m01[[171]]
prop$m01
prop$h
prop$m10
unlist(mcmc$m01)
### Execute large-scale outbreak reconstruction algorithm
set.seed(230)
## Libraries
library(ape)
library(Rcpp)
library(igraph)
library(ggraph)
library(cowplot)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
sourceCpp("cpp_subroutines.cpp")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
## Unhash these for regular run
init <- initialize(init_mst = T)
#init <- initialize()
mcmc <- init[[1]]
data <- init[[2]]
data$n_local = 10
data$sample_every = 10
data$n_global = 1
#mcmc$psi <- 0.1 / (1.5 + 0.1)
## Unhash these for run on pre-computed data and initial MCMC
# load("data.RData")
# load("mcmc.RData")
output <- list()
liks <- c()
for (r in 1:data$n_global) {
# For reproducible results
#set.seed(r)
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Chop up the tree into pieces
breakdowns <- breakdown(mcmc, data)
mcmcs <- breakdowns[[1]]
datas <- breakdowns[[2]]
message(paste("Parallelizing over", length(mcmcs), "cores..."))
# Run MCMC in parallel over each subtree
# Make the cluster
# cl <- makeCluster(length(mcmcs))
#
# all_res <- parallel::parLapply(
#   cl,
#   1:length(mcmcs),
#   function(i, mcmcs, datas){
#     source("likelihood.R")
#     source("moves.R")
#     source("prior.R")
#     source("subroutines.R")
#     source("local_mcmc.R")
#
#     set.seed(213)
#
#     local_mcmc(mcmcs[[i]], datas[[i]])
#   },
#   mcmcs = mcmcs,
#   datas = datas
# )
#
# stopCluster(cl)
all_res <- parallel::mclapply(
1:length(mcmcs),
function(i, mcmcs, datas){
local_mcmc(mcmcs[[i]], datas[[i]])
},
mcmcs = mcmcs,
datas = datas,
mc.set.seed = F,
mc.cores = length(mcmcs)
)
#...or run in series
# all_res <- list()
# for (j in 1:length(mcmcs)) {
#   all_res[[j]] <- local_mcmc(mcmcs[[j]], datas[[j]])
# }
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, datas, mcmc, data)
# Record amalgamated results, filtering to parameters of interest
for (i in 1:length(amalgam)) {
output <- c(output, list(
amalgam[[i]][data$record]
))
}
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
message(paste(r, "global iterations complete. Log-likelihood =", round(liks[r], 2)))
print(plot_current(mcmc$h, data$n_obs))
#print(mcmc$w)
print(mcmc$mu)
print(mcmc$p)
print(length(unlist(mcmc$m01)) + length(unlist(mcmc$m10)))
#print(data$s - mcmc$t[1:data$n_obs])
#print(mcmc$lambda)
#print(mcmc$h)
# print(mcmc$a_g)
# if(r == 10){
#   data$n_subtrees <- 3
# }
}
### Execute large-scale outbreak reconstruction algorithm
set.seed(231)
## Libraries
library(ape)
library(Rcpp)
library(igraph)
library(ggraph)
library(cowplot)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
sourceCpp("cpp_subroutines.cpp")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
## Unhash these for regular run
init <- initialize(init_mst = T)
#init <- initialize()
mcmc <- init[[1]]
data <- init[[2]]
data$n_local = 10
data$sample_every = 10
data$n_global = 1000
output <- list()
liks <- c()
for (r in 1:data$n_global) {
# For reproducible results
#set.seed(r)
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Chop up the tree into pieces
breakdowns <- breakdown(mcmc, data)
mcmcs <- breakdowns[[1]]
datas <- breakdowns[[2]]
message(paste("Parallelizing over", length(mcmcs), "cores..."))
# Run MCMC in parallel over each subtree
# Make the cluster
# cl <- makeCluster(length(mcmcs))
#
# all_res <- parallel::parLapply(
#   cl,
#   1:length(mcmcs),
#   function(i, mcmcs, datas){
#     source("likelihood.R")
#     source("moves.R")
#     source("prior.R")
#     source("subroutines.R")
#     source("local_mcmc.R")
#
#     set.seed(213)
#
#     local_mcmc(mcmcs[[i]], datas[[i]])
#   },
#   mcmcs = mcmcs,
#   datas = datas
# )
#
# stopCluster(cl)
all_res <- parallel::mclapply(
1:length(mcmcs),
function(i, mcmcs, datas){
local_mcmc(mcmcs[[i]], datas[[i]])
},
mcmcs = mcmcs,
datas = datas,
mc.set.seed = F,
mc.cores = length(mcmcs)
)
#...or run in series
# all_res <- list()
# for (j in 1:length(mcmcs)) {
#   all_res[[j]] <- local_mcmc(mcmcs[[j]], datas[[j]])
# }
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, datas, mcmc, data)
# Record amalgamated results, filtering to parameters of interest
for (i in 1:length(amalgam)) {
output <- c(output, list(
amalgam[[i]][data$record]
))
}
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
message(paste(r, "global iterations complete. Log-likelihood =", round(liks[r], 2)))
print(plot_current(mcmc$h, data$n_obs))
#print(mcmc$w)
print(mcmc$mu)
print(mcmc$p)
print(length(unlist(mcmc$m01)) + length(unlist(mcmc$m10)))
#print(data$s - mcmc$t[1:data$n_obs])
#print(mcmc$lambda)
#print(mcmc$h)
# print(mcmc$a_g)
# if(r == 10){
#   data$n_subtrees <- 3
# }
}
rates <- c()
times <- c()
for (i in 2:mcmc$n) {
rates[i] <- ((length(mcmc$m01[[i]]) + length(mcmc$m10[[i]])) / data$n_bases)
times[i] <- (mcmc$t[i] - mcmc$t[mcmc$h[i]])
}
plot(times, rates)
mean(rates/times, na.rm = T)
plot(times, mcmc$w+1)
mean(times/ (mcmc$w + 1), na.rm = T)
print(data$s - mcmc$t[1:data$n_obs])
log(1/sqrt(mcmc$p)) / mcmc$lambda / log(1000) + 1/mcmc$lambda
mcmc$mx1
mcmc$m10
mcmc$mxy
### Execute large-scale outbreak reconstruction algorithm
set.seed(232)
## Libraries
library(ape)
library(Rcpp)
library(igraph)
library(ggraph)
library(cowplot)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
sourceCpp("cpp_subroutines.cpp")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
## Unhash these for regular run
init <- initialize(init_mst = T)
#init <- initialize()
mcmc <- init[[1]]
data <- init[[2]]
data$n_local = 10
data$sample_every = 10
data$n_global = 1000
#mcmc$psi <- 0.1 / (1.5 + 0.1)
output <- list()
liks <- c()
for (r in 1:data$n_global) {
# For reproducible results
#set.seed(r)
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Chop up the tree into pieces
breakdowns <- breakdown(mcmc, data)
mcmcs <- breakdowns[[1]]
datas <- breakdowns[[2]]
message(paste("Parallelizing over", length(mcmcs), "cores..."))
# Run MCMC in parallel over each subtree
# Make the cluster
# cl <- makeCluster(length(mcmcs))
#
# all_res <- parallel::parLapply(
#   cl,
#   1:length(mcmcs),
#   function(i, mcmcs, datas){
#     source("likelihood.R")
#     source("moves.R")
#     source("prior.R")
#     source("subroutines.R")
#     source("local_mcmc.R")
#
#     set.seed(213)
#
#     local_mcmc(mcmcs[[i]], datas[[i]])
#   },
#   mcmcs = mcmcs,
#   datas = datas
# )
#
# stopCluster(cl)
all_res <- parallel::mclapply(
1:length(mcmcs),
function(i, mcmcs, datas){
local_mcmc(mcmcs[[i]], datas[[i]])
},
mcmcs = mcmcs,
datas = datas,
mc.set.seed = F,
mc.cores = length(mcmcs)
)
#...or run in series
# all_res <- list()
# for (j in 1:length(mcmcs)) {
#   all_res[[j]] <- local_mcmc(mcmcs[[j]], datas[[j]])
# }
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, datas, mcmc, data)
# Record amalgamated results, filtering to parameters of interest
for (i in 1:length(amalgam)) {
output <- c(output, list(
amalgam[[i]][data$record]
))
}
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
message(paste(r, "global iterations complete. Log-likelihood =", round(liks[r], 2)))
print(plot_current(mcmc$h, data$n_obs))
#print(mcmc$w)
print(mcmc$mu)
print(mcmc$p)
print(length(unlist(mcmc$m01)) + length(unlist(mcmc$m10)))
#print(data$s - mcmc$t[1:data$n_obs])
#print(mcmc$lambda)
#print(mcmc$h)
# print(mcmc$a_g)
# if(r == 10){
#   data$n_subtrees <- 3
# }
}
rates <- c()
times <- c()
for (i in 2:mcmc$n) {
rates[i] <- ((length(mcmc$m01[[i]]) + length(mcmc$m10[[i]])) / data$n_bases)
times[i] <- (mcmc$t[i] - mcmc$t[mcmc$h[i]])
}
plot(times, rates)
mean(rates/times, na.rm = T)
plot(times, mcmc$w+1)
mean(times/ (mcmc$w + 1), na.rm = T)
sum(rates, na.rm = T) / sum(times, na.rm = T)
mean(rates/times, na.rm = T)
which(times > 50 & rates == 0)
i = 11
data$s[11]
mcmc$h[11]
mcmc$h[18]
rates/times
plot(rates/times)
max(data$s)
343/966/365/29903
343/966/29903
sum(times, na.rm = T)
sum(rates, na.rm = T)
sum(rates, na.rm = T)*29903
source("~/Desktop/thesis/main.R", echo=TRUE)
sum(rates, na.rm = T) / sum(times, na.rm = T)
mcmc$m01
mcmc$h[48]
mcmc$m10
mcmc$m01
hist(mcmc$t)
mcmc$m01
which(times > 80 & rates == 0)
which(times > 70 & rates == 0)
which(rates == 0)
which(times > 60 & rates == 0)
which(times > 50 & rates == 0)
which(times > 55 & rates == 0)
which(times > 58 & rates == 0)
which(times > 59 & rates == 0)
mcmc$h[18]
mcmc$h[49]
mcmc$h[42]
mcmc$h[85]
rates[60]
rates[85]
rates[which(mcmc$h == 201)]
times[which(mcmc$h == 201)]
mcmc$w
data$n_obs
mcmc$m01[which(mcmc$h == 201)]
rates[which(mcmc$h == 201)]/times[which(mcmc$h == 201)]
