output <- list()
liks <- c()
for (r in 1:data$n_global) {
# For reproducible results
#set.seed(r)
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Chop up the tree into pieces
breakdowns <- breakdown(mcmc, data)
mcmcs <- breakdowns[[1]]
datas <- breakdowns[[2]]
message(paste("Parallelizing over", length(mcmcs), "cores..."))
save(mcmcs, file = "mcmcs.RData")
# Run MCMC in parallel over each subtree
# Make the cluster
# cl <- makeCluster(length(mcmcs))
#
# all_res <- parallel::parLapply(
#   cl,
#   1:length(mcmcs),
#   function(i, mcmcs, datas){
#     source("likelihood.R")
#     source("moves.R")
#     source("prior.R")
#     source("subroutines.R")
#     source("local_mcmc.R")
#
#     set.seed(213)
#
#     local_mcmc(mcmcs[[i]], datas[[i]])
#   },
#   mcmcs = mcmcs,
#   datas = datas
# )
#
# stopCluster(cl)
all_res <- parallel::mclapply(
1:length(mcmcs),
function(i, mcmcs, datas){
local_mcmc(mcmcs[[i]], datas[[i]])
},
mcmcs = mcmcs,
datas = datas,
mc.set.seed = F,
mc.cores = length(mcmcs)
)
#...or run in series
# all_res <- list()
# for (j in 1:length(mcmcs)) {
#   all_res[[j]] <- local_mcmc(mcmcs[[j]], datas[[j]])
# }
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, datas, mcmc, data)
# Record amalgamated results, filtering to parameters of interest
for (i in 1:length(amalgam)) {
output <- c(output, list(
amalgam[[i]][data$record]
))
}
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
message(paste(r, "global iterations complete. Log-likelihood =", round(liks[r], 2)))
#print(plot_current(mcmc$h, data$n_obs))
#print(mcmc$w)
print(mcmc$mu)
print(mcmc$p)
print(mcmc$lambda)
# print(mcmc$a_g)
# if(r == 10){
#   data$n_subtrees <- 3
# }
}
return(list(
liks, output
))
}
#hehe <- run_mcmc(mcmc, data)
### Sensitivity analysis
# Parameters to assess sensitivity: (as changes from default values)
a_gs <- c(4, 6) # Default = 5
lambda_gs <- a_gs/5 # Default = 1. Also update a_g to maintain mean of 5. Corresponds to variance of 5 (default), 25, 1
a_ss <- c(4, 6) # Default = 5
lambda_ss <- a_ss/5 # Default = 1. Also update a_s to maintain mean of 5. Corresponds to variance of 5 (default), 25, 1
rhos <- c(0.05, 0.2) # Default = 0.1. Also update psi = rho / (2.5 + rho)
psis <- 0.1 / (c(1.5, 3.5) + 0.1)
# jth column is corresponds to each of the above params, in order
combos <- matrix(c(5, 1, 5, 1, 0.1, 0.1/(2.5 + 0.1)), nrow = 12, ncol = 6, byrow = T)
combos[1:2, 1] <- a_gs
combos[3:4, 1] <- lambda_gs * 5
combos[3:4, 2] <- lambda_gs
combos[5:6, 3] <- a_ss
combos[7:8, 3] <- lambda_ss * 5
combos[7:8, 4] <- lambda_ss
combos[9:10, 5] <- rhos
combos[9:10, 6] <- rhos / (2.5 + rhos)
combos[11:12, 6] <- psis
sensitivity <- list()
all_liks <- list()
for(i in 1:nrow(combos)){
mcmc$a_g <- combos[i, 1]
mcmc$lambda_g <- combos[1, 2]
mcmc$a_s <- combos[i, 3]
mcmc$lambda_s <- combos[i, 4]
mcmc$rho <- combos[i, 5]
mcmc$psi <- combos[i, 6]
out <- run_mcmc(mcmc, data)
all_liks[[i]] <- out[[1]]
sensitivity[[i]] <- out[[2]]
print(i)
}
### Execute large-scale outbreak reconstruction algorithm
set.seed(226)
## Libraries
library(ape)
library(Rcpp)
library(igraph)
library(ggraph)
library(cowplot)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
## Unhash these for regular run
init <- initialize()
mcmc <- init[[1]]
data <- init[[2]]
#data$n_subtrees = 12
data$n_local = 10
data$sample_every = 10
data$n_global = 10000
data$N <- 100000
## Unhash these for run on pre-computed data and initial MCMC
# load("data.RData")
# load("mcmc.RData")
### M-H algo
run_mcmc <- function(mcmc, data){
output <- list()
liks <- c()
for (r in 1:data$n_global) {
# For reproducible results
#set.seed(r)
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Chop up the tree into pieces
breakdowns <- breakdown(mcmc, data)
mcmcs <- breakdowns[[1]]
datas <- breakdowns[[2]]
message(paste("Parallelizing over", length(mcmcs), "cores..."))
save(mcmcs, file = "mcmcs.RData")
# Run MCMC in parallel over each subtree
# Make the cluster
# cl <- makeCluster(length(mcmcs))
#
# all_res <- parallel::parLapply(
#   cl,
#   1:length(mcmcs),
#   function(i, mcmcs, datas){
#     source("likelihood.R")
#     source("moves.R")
#     source("prior.R")
#     source("subroutines.R")
#     source("local_mcmc.R")
#
#     set.seed(213)
#
#     local_mcmc(mcmcs[[i]], datas[[i]])
#   },
#   mcmcs = mcmcs,
#   datas = datas
# )
#
# stopCluster(cl)
all_res <- parallel::mclapply(
1:length(mcmcs),
function(i, mcmcs, datas){
local_mcmc(mcmcs[[i]], datas[[i]])
},
mcmcs = mcmcs,
datas = datas,
mc.set.seed = F,
mc.cores = length(mcmcs)
)
#...or run in series
# all_res <- list()
# for (j in 1:length(mcmcs)) {
#   all_res[[j]] <- local_mcmc(mcmcs[[j]], datas[[j]])
# }
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, datas, mcmc, data)
# Record amalgamated results, filtering to parameters of interest
for (i in 1:length(amalgam)) {
output <- c(output, list(
amalgam[[i]][data$record]
))
}
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
message(paste(r, "global iterations complete. Log-likelihood =", round(liks[r], 2)))
#print(plot_current(mcmc$h, data$n_obs))
#print(mcmc$w)
print(mcmc$mu)
print(mcmc$p)
print(mcmc$lambda)
# print(mcmc$a_g)
# if(r == 10){
#   data$n_subtrees <- 3
# }
}
return(list(
liks, output
))
}
#hehe <- run_mcmc(mcmc, data)
### Sensitivity analysis
# Parameters to assess sensitivity: (as changes from default values)
a_gs <- c(4, 6) # Default = 5
lambda_gs <- a_gs/5 # Default = 1. Also update a_g to maintain mean of 5. Corresponds to variance of 5 (default), 25, 1
a_ss <- c(4, 6) # Default = 5
lambda_ss <- a_ss/5 # Default = 1. Also update a_s to maintain mean of 5. Corresponds to variance of 5 (default), 25, 1
rhos <- c(0.05, 0.2) # Default = 0.1. Also update psi = rho / (2.5 + rho)
psis <- 0.1 / (c(1.5, 3.5) + 0.1)
# jth column is corresponds to each of the above params, in order
combos <- matrix(c(5, 1, 5, 1, 0.1, 0.1/(2.5 + 0.1)), nrow = 12, ncol = 6, byrow = T)
combos[1:2, 1] <- a_gs
combos[3:4, 1] <- lambda_gs * 5
combos[3:4, 2] <- lambda_gs
combos[5:6, 3] <- a_ss
combos[7:8, 3] <- lambda_ss * 5
combos[7:8, 4] <- lambda_ss
combos[9:10, 5] <- rhos
combos[9:10, 6] <- rhos / (2.5 + rhos)
combos[11:12, 6] <- psis
sensitivity <- list()
all_liks <- list()
for(i in 1:nrow(combos)){
mcmc$a_g <- combos[i, 1]
mcmc$lambda_g <- combos[1, 2]
mcmc$a_s <- combos[i, 3]
mcmc$lambda_s <- combos[i, 4]
mcmc$rho <- combos[i, 5]
mcmc$psi <- combos[i, 6]
out <- run_mcmc(mcmc, data)
all_liks[[i]] <- out[[1]]
sensitivity[[i]] <- out[[2]]
print(i)
}
## Get adjacency matrix. Ancestor > data$n_obs doesn't count for anything. Indirect transmission OK
get_adj <- function(run, n_obs){
out <- matrix(0, nrow = n_obs, ncol = n_obs)
len <- length(run)
for (i in (len*0.1):len) {
h <- run[[i]]$h
present <- which(!is.na(h) & h <= n_obs)
present <- present[present <= n_obs]
out[cbind(h[present], present)] <- out[cbind(h[present], present)] + 1
}
return(out / (0.9*len))
}
adjs <- lapply(sensitivity, get_adj, n_obs = data$n_obs)
# Run on default settings
default <- run_mcmc(mcmc, data)
default_adj <- get_adj(default[[2]], data$n_obs)
# Histogram of change in adjacency matrix
network_change <- function(i){
change <- as.vector(adjs[[i]] - default_adj)
change <- change[abs(change) > 0]
p <- ggplot(data.frame(x = change), aes(x = x)) +
geom_histogram(aes(y=after_stat(density)), binwidth = 0.1, boundary = 0.1, color = "white", fill = "grey") +
xlab("Change in Posterior Probability") +
ylab("Probability Density") +
#scale_y_continuous(trans='log2') +
xlim(-1, 1) +
theme_minimal()
p
}
hists <- lapply(1:12, network_change)
all_hists <- plot_grid(
hists[[1]],
hists[[2]],
hists[[3]],
hists[[4]],
hists[[5]],
hists[[6]],
hists[[7]],
hists[[8]],
hists[[9]],
hists[[10]],
hists[[11]],
hists[[12]],
ncol = 3,
labels = "AUTO"
)
ggsave("./figs/hist.pdf", width = 7.8, height = 9)
ggsave("./figs/hist.png", width = 7.8, height = 9)
## Next up, density plots of mu
param_dens <- function(i, param){
run <- sensitivity[[i]]
out <- c()
len <- length(run)
for (j in (len*0.1):len) {
out <- c(out, (run[[j]][[param]]))
}
p <- ggplot(data.frame(x = out), aes(x = x)) +
geom_histogram(aes(y=after_stat(density)), color = "white", fill = "grey") +
xlab(paste("Value of", param)) +
ylab("Probability Density") +
scale_x_continuous(breaks = signif(seq(min(out), max(out), by = (max(out) - min(out)) / 2) , 2)) +
scale_y_continuous(labels = function(x) format(x, scientific = TRUE)) +
theme_minimal() +
theme(plot.margin = margin(t = 0, r = 0.2, b = 0, l = 0, unit = "in"))
p
}
output_plots <- function(param){
dens <- lapply(1:12, param_dens, param = param)
all_dens <- plot_grid(
dens[[1]],
dens[[2]],
dens[[3]],
dens[[4]],
dens[[5]],
dens[[6]],
dens[[7]],
dens[[8]],
dens[[9]],
dens[[10]],
dens[[11]],
dens[[12]],
ncol = 3,
labels = "AUTO"
)
ggsave(paste0("./figs/", param, ".pdf"), width = 7.8, height = 10.2)
ggsave(paste0("./figs/", param, ".png"), width = 7.8, height = 10.2)
}
output_plots("mu")
output_plots("p")
output_plots("lambda")
output_plots("b")
# Adjusted reproductive numbers
# Solve log(R_0) / a_g = log(2.5)/5
# r0s <- exp(a_gs * log(2.5)/5)
# combos[1:2, 6] <- 0.1 / (r0s + 0.1)
i = 1
change <- as.vector(adjs[[i]] - default_adj)
change <- change[abs(change) > 0]
p <- ggplot(data.frame(x = change), aes(x = x)) +
geom_histogram(aes(y=after_stat(density)), binwidth = 0.1, boundary = 0.1, color = "white", fill = "grey") +
xlab("Change in Posterior Probability") +
ylab("Probability Density") +
#scale_y_continuous(trans='log2') +
xlim(-1, 1) +
theme_minimal()
change
max(change)
min(change)
sum(change > 0.1)
sum(change < -0.1)
cons
cons <- read.FASTA("~/Desktop/input_data_huge/aligned.fasta")
date <- read.csv("~/Desktop/input_data_huge/date.csv")
sub <- meta[meta$Program2 == "Prison", ]
keep <- which(names(cons) %in% sub$case)
cons <- cons[keep]
date <- date[keep,]
names(cons)
meta <- read.csv("~/Desktop/input_data_huge/metadata.csv")
meta <- meta[match(filter_names, meta$case), ]
meta <- read.csv("~/Desktop/input_data_huge/metadata.csv")
date <- read.csv("~/Desktop/input_data_huge/date.csv")
sub <- meta[meta$Program2 == "Prison", ]
keep <- which(names(cons) %in% sub$case)
cons <- cons[keep]
date <- date[keep,]
names(cons)
keep
sub <- meta[meta$Program2 == "Prison", ]
cons <- read.FASTA("~/Desktop/input_data_huge/aligned.fasta")
keep <- which(names(cons) %in% sub$case)
cons <- cons[keep]
date <- date[keep,]
names(cons)
i - 2
i = 2
change <- as.vector(adjs[[i]] - default_adj)
change <- change[abs(change) > 0]
p <- ggplot(data.frame(x = change), aes(x = x)) +
geom_histogram(aes(y=after_stat(density)), binwidth = 0.1, boundary = 0.1, color = "white", fill = "grey") +
xlab("Change in Posterior Probability") +
ylab("Probability Density") +
#scale_y_continuous(trans='log2') +
xlim(-1, 1) +
theme_minimal()
p
max(abs(change))
sort(change)
rev(sort(change))
i=3
change <- as.vector(adjs[[i]] - default_adj)
change <- change[abs(change) > 0]
p <- ggplot(data.frame(x = change), aes(x = x)) +
geom_histogram(aes(y=after_stat(density)), binwidth = 0.1, boundary = 0.1, color = "white", fill = "grey") +
xlab("Change in Posterior Probability") +
ylab("Probability Density") +
#scale_y_continuous(trans='log2') +
xlim(-1, 1) +
theme_minimal()
p
min(change)
max(change)
i=1
change <- as.vector(adjs[[i]] - default_adj)
change <- change[abs(change) > 0]
p <- ggplot(data.frame(x = change), aes(x = x)) +
geom_histogram(aes(y=after_stat(density)), binwidth = 0.1, boundary = 0.1, color = "white", fill = "grey") +
xlab("Change in Posterior Probability") +
ylab("Probability Density") +
#scale_y_continuous(trans='log2') +
xlim(-1, 1) +
theme_minimal()
p
max(change)
i = 4
change <- as.vector(adjs[[i]] - default_adj)
change <- change[abs(change) > 0]
p <- ggplot(data.frame(x = change), aes(x = x)) +
geom_histogram(aes(y=after_stat(density)), binwidth = 0.1, boundary = 0.1, color = "white", fill = "grey") +
xlab("Change in Posterior Probability") +
ylab("Probability Density") +
#scale_y_continuous(trans='log2') +
xlim(-1, 1) +
theme_minimal()
p
max(change)
min(change)
mcmc <- default[[10000]]
mcmc <- default[[1000]]
mcmc <- default[[2]][[10000]]
plot_current(mcmc$h, data$n_obs)
mcmc0 <- mcmc
data0 <- data
### Execute large-scale outbreak reconstruction algorithm
set.seed(220)
## Libraries
library(ape)
library(Rcpp)
#library(igraph)
#library(ggraph)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
load("data_init.RData")
load("mcmc_init.RData")
filters
filters <- NULL
## Filters
if(is.null(filters)){
filters <- list(
af = 0.03,
dp = 100,
sb = 10
)
if(file.exists("./input_data/problematic.csv")){
filters$common <- read.csv("./input_data/problematic.csv")[,1]
}else{
filters$common <- integer(0)
}
}
data$N <- 100000 #population size
data$record
record = c("n", "h", "w", "t", "b", "a_g", "lambda_g", "a_s", "lambda_s", "mu", "p", "v", "lambda", "rho", "psi")
data$record <- record
#data$n_subtrees <- 3
data$filters <- filters
data$sample_every
data$n_global
data$n_local
mcmc$h
mcmc$lambda <- 9
mcmc$e_lik <- e_lik(mcmc, data)
mcmc$g_lik <- c(NA, sapply(2:n, g_lik, mcmc = mcmc, data = data))
n <- data$n_obs
mcmc$g_lik <- c(NA, sapply(2:n, g_lik, mcmc = mcmc, data = data))
mcmc$prior <- prior(mcmc)
moves$b(mcmc, data)
moves$mu(mcmc, data)
moves$lambda(mcmc, data)
save(mcmc, file = "mcmc_init.RData")
save(data, file = "data_init.RData")
data$N
data$n_subtrees
# Chop up the tree into pieces
breakdowns <- breakdown(mcmc, data)
mcmcs <- breakdowns[[1]]
datas <- breakdowns[[2]]
message(paste("Parallelizing over", length(mcmcs), "cores..."))
?mclapply
data$snvs
mcmc <- mcmc0
data <- data0
datas <- 0
