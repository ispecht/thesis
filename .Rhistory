for (r in 1:data$n_global) {
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Initially: chop up the tree into just one piece. After r sufficiently large, chop into more pieces
mcmcs <- breakdown(mcmc, data)
# Run MCMC in parallel over each subtree
#all_res <- parallel::mclapply(mcmcs, local_mcmc, data = data, mc.cores = data$n_subtrees)
#...or run in series
all_res <- list()
for (j in 1:data$n_subtrees) {
all_res[[j]] <- local_mcmc(mcmcs[[j]], data)
}
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, data)
# Record amalgamated results
output <- c(output, amalgam)
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
print(paste(r * data$n_local * data$n_subtrees, "iterations complete. Log-likelihood =", round(liks[r], 2)))
print(plot_current(mcmc$h, data$n_obs))
print(mcmc$w)
# if(r == 10){
#   data$n_subtrees <- 3
# }
}
mcmc$t[12]
s[12]
data$s[12]
### Execute large-scale outbreak reconstruction algorithm
set.seed(213)
## Libraries
library(ape)
library(Rcpp)
library(igraph)
library(ggraph)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
init <- initialize()
mcmc <- init[[1]]
data <- init[[2]]
### M-H algo
output <- list()
liks <- c()
for (r in 1:data$n_global) {
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Initially: chop up the tree into just one piece. After r sufficiently large, chop into more pieces
mcmcs <- breakdown(mcmc, data)
# Run MCMC in parallel over each subtree
#all_res <- parallel::mclapply(mcmcs, local_mcmc, data = data, mc.cores = data$n_subtrees)
#...or run in series
all_res <- list()
for (j in 1:data$n_subtrees) {
all_res[[j]] <- local_mcmc(mcmcs[[j]], data)
}
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, data)
# Record amalgamated results
output <- c(output, amalgam)
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
print(paste(r * data$n_local * data$n_subtrees, "iterations complete. Log-likelihood =", round(liks[r], 2)))
print(plot_current(mcmc$h, data$n_obs))
print(mcmc$w)
if(r == 10){
data$n_subtrees <- 3
}
}
global_mcmc(mcmc, data)
global_mcmc(mcmc, data)
global_mcmc(mcmc, data)
moves$b(mcmc, data)
mcmc
mcmc$g_lik
mcmc$e_lik
# Proposal
prop <- mcmc
prop$b <- rnorm(1, mcmc$b, 0.1)
prop$e_lik <- e_lik(prop, data)
prop$g_lik[2:mcmc$n] <- sapply(2:mcmc$n, g_lik, mcmc = prop, data = data)
sapply(2:mcmc$n, g_lik, mcmc = prop, data = data)
mcmc0 <- mcmc
mcmc <- prop
g_lik(mcmc, data, 2)
sapply(2:50, g_lik, mcmc = prop, data = data)
sapply(2:40, g_lik, mcmc = prop, data = data)
sapply(2:30, g_lik, mcmc = prop, data = data)
sapply(2:10, g_lik, mcmc = prop, data = data)
sapply(2:3, g_lik, mcmc = prop, data = data)
sapply(2:4, g_lik, mcmc = prop, data = data)
sapply(2:5, g_lik, mcmc = prop, data = data)
sapply(2:7, g_lik, mcmc = prop, data = data)
sapply(2:9, g_lik, mcmc = prop, data = data)
sapply(2:8, g_lik, mcmc = prop, data = data)
i = 8
mcmc$v < 0 | mcmc$mu < 0 | mcmc$p < 0 | mcmc$b < 0 | mcmc$b > 1 | mcmc$w[i] < 0
# Time of end of expo growth phase for ancestor of i
g <- mcmc$t[mcmc$h[i]] - (mcmc$mu/mcmc$p)*log(mcmc$v) - log(mcmc$p)/2
# Evolutionary time
delta_t <- mcmc$t[i] - g
delta_t < 0
mcmc$t[i]
g
log(mcmc$v)
mcmc$t[mcmc$h[i]] - (mcmc$mu/mcmc$p)*log(mcmc$v) - log(mcmc$p)/2
mcmc$h[i]
mcmc$t
mcmc$h
length(mcmc$h)
mcmc$n
all_res[[1]]
all_res[[1]]$n
data$n_local
data$sample_every
all_res[[1]][[1]]$n
all_res[[2]][[1]]$n
all_res[[3]][[1]]$n
mcmc$n
all_res[[1]][[1]]$cluster
all_res[[2]][[1]]$cluster
all_res[[3]][[1]]$cluster
# Number of samples for each subtree
n_samples <- length(all_res[[1]])
# Number of subtrees
n_subtrees <- data$n_subtrees
# Create a list to store the amalgamated results
res <- list()
i = 1
# Get the ancestral cluster of each cluster
anc_clusters <- c()
roots <- c()
for (j in 1:n_subtrees) {
roots[j] <- all_res[[j]][[i]]$root
anc <- all_res[[j]][[i]]$h[all_res[[j]][[i]]$root]
if(is.na(anc)){
anc_clusters[j] <- NA
}else{
for (k in 1:n_subtrees) {
if(anc %in% all_res[[k]][[i]]$cluster | anc == all_res[[k]][[i]]$root){
anc_clusters[j] <- k
}
}
}
}
all_res[[j]][[i]]$h
# Get the ancestral cluster of each cluster
anc_clusters <- c()
roots <- c()
for (j in 1:n_subtrees) {
roots[j] <- all_res[[j]][[i]]$root
anc <- all_res[[j]][[i]]$h[all_res[[j]][[i]]$root]
print(anc)
if(is.na(anc)){
anc_clusters[j] <- NA
}else{
for (k in 1:n_subtrees) {
if(anc %in% all_res[[k]][[i]]$cluster | anc == all_res[[k]][[i]]$root){
anc_clusters[j] <- k
}
}
}
}
# First determine who the unobserved hosts are in each cluster, so that they may be re-indexed
unobs <- list()
cls <- list() # Cluster including roots of upstream clusters, as
for (j in 1:n_subtrees) {
cls[[j]] <- c(roots[which(anc_clusters == j)], all_res[[j]][[i]]$cluster)
unobs[[j]] <- cls[[j]][cls[[j]] > data$n_obs]
}
cls
sort(unlist(cls))
### Execute large-scale outbreak reconstruction algorithm
set.seed(213)
## Libraries
library(ape)
library(Rcpp)
library(igraph)
library(ggraph)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
init <- initialize()
mcmc <- init[[1]]
data <- init[[2]]
### M-H algo
output <- list()
liks <- c()
for (r in 1:data$n_global) {
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Initially: chop up the tree into just one piece. After r sufficiently large, chop into more pieces
mcmcs <- breakdown(mcmc, data)
# Run MCMC in parallel over each subtree
all_res <- parallel::mclapply(mcmcs, local_mcmc, data = data, mc.cores = data$n_subtrees)
#...or run in series
# all_res <- list()
# for (j in 1:data$n_subtrees) {
#   all_res[[j]] <- local_mcmc(mcmcs[[j]], data)
# }
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, data)
# Record amalgamated results
output <- c(output, amalgam)
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
print(paste(r * data$n_local * data$n_subtrees, "iterations complete. Log-likelihood =", round(liks[r], 2)))
print(plot_current(mcmc$h, data$n_obs))
print(mcmc$w)
if(r == 10){
data$n_subtrees <- 3
}
}
mcmc$t[71]
data$s[71]
### Execute large-scale outbreak reconstruction algorithm
set.seed(213)
## Libraries
library(ape)
library(Rcpp)
library(igraph)
library(ggraph)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
## Filters
filters <- list(
af = 0.03,
dp = 100,
sb = 10
)
## Data Processing
# Load the reference sequence
ref_genome <- read.FASTA("./input_data/ref.fasta")
# Length of genome
n_bases <- length(ref_genome[[1]])
# Load the FASTA of sequences
fasta <- read.FASTA("./input_data/aligned.fasta")
# The first genome is itself the ref genome
fasta <- c(ref_genome, fasta)
# Number of samples
n <- length(fasta)
# Names of sequences
names <- names(fasta)
# VCF files present
vcfs <- list.files("./input_data/vcf/")
# Date
date <- read.csv("input_data/date.csv")
s <- c()
for (i in 1:n) {
# Check if we have a VCF file
included <- grepl(names[i], date[,1])
if(sum(included) >= 2){
stop(paste("Multiple sample collection dates found for sequence", names[i]))
}else if(sum(included) == 1){
s[i] <- date[,2][included]
}else{
s[i] <- NA
}
}
s[1] <- 0
## List of SNVs present per sample
snvs <- list()
for (i in 1:n) {
# Check if we have a VCF file
included <- grepl(names[i], vcfs)
if(sum(included) >= 2){
stop(paste("Multiple VCF files found for sequence", names[i]))
}else if(sum(included) == 1){
vcf <- read.table(paste0("./input_data/vcf/", vcfs[included]))
snvs[[i]] <- genetic_info(ref_genome[[1]], fasta[[i]], filters = filters, vcf = vcf)
}else{
snvs[[i]] <- genetic_info(ref_genome[[1]], fasta[[i]], filters = filters)
}
}
# Compile vectors of all positions with SNVs (may have duplicates) and all SNVs (unique)
all_pos <- c()
all_snv <- c()
for (i in 1:n) {
calls <- snvs[[i]]$snv$call
new <- which(!(calls %in% all_snv))
all_snv <- c(all_snv, calls[new])
all_pos <- c(all_pos, snvs[[i]]$snv$pos[new])
if(!is.null(snvs[[i]]$isnv)){
calls <- snvs[[i]]$isnv$call
new <- which(!(calls %in% all_snv))
all_snv <- c(all_snv, calls[new])
all_pos <- c(all_pos, snvs[[i]]$isnv$pos[new])
}
}
# Remove irrelevant missing site info; add SNVs with missing data
for (i in 1:n) {
# Which positions in all_pos are detected in the missing sites in the sample?
present <- which(all_pos %in% snvs[[i]]$missing$pos)
# Change missing$pos to be a vector of these sites (may have duplicates)
snvs[[i]]$missing$pos <- all_pos[present]
# Add a new vector of the SNVs for which there's no information
snvs[[i]]$missing$call <- all_snv[present]
}
### Initialize MCMC and
## For MCMC initialization: minimum spanning tree
if(init_mst){
snv_dist <- ape::dist.dna(fasta, "N")
tree <- ape::mst(snv_dist)
init_h <- adj_to_anc(tree, 1)
}
init_mst
init_mst <- T
## For MCMC initialization: minimum spanning tree
if(init_mst){
snv_dist <- ape::dist.dna(fasta, "N")
tree <- ape::mst(snv_dist)
init_h <- adj_to_anc(tree, 1)
}
init_h
which(init_h == 1)
data <- list()
data$s <- s
data$N <- 10000 #population size
data$n_obs <- n # number of observed hosts, plus 1 (index case)
data$n_bases <- n_bases
data$snvs <- snvs
data$eps <- 0.005 # Explore/exploit tradeoff for genotypes of new nodes
data$p_move <- 0.6
data$tau = 0.2
data$n_cores <- parallel::detectCores()
# Number of subtrees to chop into is n_cores, as long as each subtree has at least 100 people
data$n_subtrees <- max(min(data$n_cores, floor(n / 100)), 1)
data$n_global <- 50 # Number of global moves
data$n_local <- 100 # Number of local moves per global move
data$sample_every <- 100 # Per how many local moves do we draw one sample?
#data$n_subtrees <- 3
mcmc <- list()
mcmc$n <- n # number of tracked hosts
mcmc$h <- rep(1, n) # ancestors; initialized to index case
mcmc$w <- rep(0, n) # edge weights; initialized to 0
mcmc$w[1] <- 0 # For convenience
mcmc$h[1] <- NA
mcmc$t <- s - 5 # time of contracting
mcmc$m01 <- list() # fixed mutations added in each transmission link
mcmc$m10 <- list() # fixed mutations deleted in each transmission link
mcmc$m0y <- list() # 0% -> y%, 0 < y < 100
mcmc$m1y <- list() # 100% -> y%, 0 < y < 100
mcmc$mx0 <- list() # x% -> 0%, 0 < x < 100
mcmc$mx1 <- list() # x% -> 100%, 0 < x < 100
mcmc$mxy <- list() # x% -> y%, 0 < x < 100, 0 < y < 100
for (i in 1:n) {
mcmc$m01[[i]] <- snvs[[i]]$snv$call
mcmc$m10[[i]] <- character(0)
mcmc$m0y[[i]] <- snvs[[i]]$isnv$call
mcmc$m1y[[i]] <- character(0)
mcmc$mx0[[i]] <- character(0)
mcmc$mx1[[i]] <- character(0)
mcmc$mxy[[i]] <- character(0)
}
if(init_mst){
gens <- generations(init_h, 1)
max_t <- min(s[2:n] - 5)
for (g in 2:length(gens)) {
for (i in gens[[g]]) {
if(g >= 3){
anc <- ancestry(init_h, i)
for (j in 2:(length(anc) - 1)) {
mcmc <- update_genetics_upstream(mcmc, mcmc, i, anc[j])
mcmc$m01[[j]] <- setdiff(mcmc$m01[[j]], snvs[[j]]$missing$call) # Remove calls for missing positions
mcmc$m10[[j]] <- setdiff(mcmc$m10[[j]], snvs[[j]]$missing$call)
}
}
mcmc$t[i] <- max_t - 5*(length(gens) - g)
}
}
mcmc$h <- init_h
}
mcmc$b <- 0.95 # Probability bottleneck has size 1
mcmc$a_g <- 5 # shape parameter of the generation interval
mcmc$lambda_g <- 1 # rate parameter of the generation interval. FOR NOW: fixing at 1.
mcmc$a_s <- 5 # shape parameter of the sojourn interval
mcmc$lambda_s <- 1 # rate parameter of the sojourn interval. FOR NOW: fixing at 1.
mcmc$mu <- 1e-6 # mutation rate, sites/day
mcmc$p <- 1e-6 # mutation rate, sites/cycle
mcmc$v <- 1000 # burst size
mcmc$rho <- 0.1 # first parameter, NBin offspring distribution (overdispersion param)
mcmc$psi <- 0.1 / (2.5 + 0.1) # second parameter, NBin offspring distribution (computed in terms of R0)
# Functions of MCMC params
mcmc$d <- sapply(1:n, function(x){sum(mcmc$h[2:n] == x)}) # Node degrees
# Also track the epidemiological and genomic likelihoods, and prior
# The genomic likelihood we will store on a per-person basis, for efficiency purposes
mcmc$e_lik <- e_lik(mcmc, data)
mcmc$g_lik <- c(NA, sapply(2:n, g_lik, mcmc = mcmc, data = data))
mcmc$prior <- prior(mcmc)
mcmc$e_lik
mcmc$g_lik
### M-H algo
output <- list()
liks <- c()
for (r in 1:data$n_global) {
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Initially: chop up the tree into just one piece. After r sufficiently large, chop into more pieces
mcmcs <- breakdown(mcmc, data)
# Run MCMC in parallel over each subtree
all_res <- parallel::mclapply(mcmcs, local_mcmc, data = data, mc.cores = data$n_subtrees)
#...or run in series
# all_res <- list()
# for (j in 1:data$n_subtrees) {
#   all_res[[j]] <- local_mcmc(mcmcs[[j]], data)
# }
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, data)
# Record amalgamated results
output <- c(output, amalgam)
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
print(paste(r * data$n_local * data$n_subtrees, "iterations complete. Log-likelihood =", round(liks[r], 2)))
print(plot_current(mcmc$h, data$n_obs))
print(mcmc$w)
if(r == 10){
data$n_subtrees <- 3
}
}
data$s[18]
mcmc$a_g
mcmc$lambda_g
mcmc$t[18]
mm <- matrix(0, 1000, 1000)
max(min(parallel::detectCores(), floor(n / 100)), 1)
### Execute large-scale outbreak reconstruction algorithm
set.seed(213)
## Libraries
library(ape)
library(Rcpp)
library(igraph)
library(ggraph)
library(parallel)
source("likelihood.R")
source("moves.R")
source("prior.R")
source("subroutines.R")
source("initialize.R")
source("global_mcmc.R")
source("local_mcmc.R")
init <- initialize()
mcmc <- init[[1]]
data <- init[[2]]
### M-H algo
output <- list()
liks <- c()
for (r in 1:data$n_global) {
# Make global moves
mcmc <- global_mcmc(mcmc, data)
# Initially: chop up the tree into just one piece. After r sufficiently large, chop into more pieces
mcmcs <- breakdown(mcmc, data)
# Run MCMC in parallel over each subtree
all_res <- parallel::mclapply(mcmcs, local_mcmc, data = data, mc.cores = data$n_subtrees)
#...or run in series
# all_res <- list()
# for (j in 1:data$n_subtrees) {
#   all_res[[j]] <- local_mcmc(mcmcs[[j]], data)
# }
# Amalgamate results of parallel MCMC run
amalgam <- amalgamate(all_res, mcmcs, data)
# Record amalgamated results
output <- c(output, amalgam)
# "mcmc" is now the most recent result
mcmc <- amalgam[[length(amalgam)]]
#print(r)
liks <- c(liks, mcmc$e_lik + sum(mcmc$g_lik[2:mcmc$n]) + mcmc$prior)
print(paste(r * data$n_local * data$n_subtrees, "iterations complete. Log-likelihood =", round(liks[r], 2)))
print(plot_current(mcmc$h, data$n_obs))
print(mcmc$w)
if(r == 10){
data$n_subtrees <- 3
}
}
library(ape)
fasta <- read.FASTA("~/Desktop/100k/2023_03_16.aligned.fasta")
combined_vcf <- read.table("~/Desktop/100k/allvariants copy.tsv")
nrow(combined_vcf)
names <- names(fasta)
head(combined_vcf)
names
names <- gsub("\\|.*", "", names)
names
sum(names %in% combined_vcf$V9)
combined_vcf$V9
length(unique(combined_vcf$V9))
names <- gsub("\\_", "\\-", names)
combined_vcf$V9 <- gsub("\\_", "\\-", combined_vcf$V9)
sum(names %in% combined_vcf$V9)
